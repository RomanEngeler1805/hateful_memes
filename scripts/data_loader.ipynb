{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# general\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "from transformers import DistilBertModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure\n",
    "- plot images\n",
    "- text preprocessing\n",
    "- data loader\n",
    "- image augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Plot images"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset_df = pd.read_json('../data/train.jsonl', lines=True)\n",
    "\n",
    "# plot a few images together with labels\n",
    "nx = 3\n",
    "ny = 3\n",
    "\n",
    "fig, ax = plt.subplots(figsize=(16, ny*4), nrows=ny, ncols=nx)\n",
    "for i in range(ny):\n",
    "    for j in range(nx):\n",
    "        img_id = dataset_df['id'].values[i*nx+ j]\n",
    "        \n",
    "        # catch trailing 0\n",
    "        if img_id < 1e4:\n",
    "            img = cv2.imread('../data/img/0'+str(img_id)+ '.png', cv2.IMREAD_GRAYSCALE)\n",
    "        else:\n",
    "            img = cv2.imread('../data/img/'+str(img_id)+ '.png', cv2.IMREAD_GRAYSCALE)  \n",
    "        \n",
    "        # plot and remove axes\n",
    "        ax[i,j].imshow(img, cmap='gray')\n",
    "        ax[i,j].set_title('Racist' if dataset_df['label'].values[i*nx+ j] else 'Non-Racist')\n",
    "        ax[i,j].axes.get_xaxis().set_visible(False)\n",
    "        ax[i,j].axes.get_yaxis().set_visible(False)\n",
    "        \n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert requires: <br>\n",
    "- tokenization\n",
    "- special characters\n",
    "- padding\n",
    "- mask\n",
    "\n",
    "techniques to try (for other models): <br>\n",
    "- Lower casing\n",
    "- Punctuation removal\n",
    "- Stopwords removal\n",
    "- Frequent words removal\n",
    "- Rare words removal\n",
    "- Spelling correction\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- word embedding/ bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "g"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# dictionary\n",
    "data = dataset_df.to_dict(orient='records') # have been shuffled in previous step\n",
    "\n",
    "# Calculate the number of samples to include in each set.\n",
    "train_size = int(0.8 * len(data))\n",
    "val_size = len(data) - train_size\n",
    "\n",
    "# train valid split\n",
    "train_data, valid_data = random_split(data, [train_size, val_size])\n",
    "\n",
    "#train_size = int(0.05 * len(valid_data))\n",
    "#val_size = len(valid_data) - train_size\n",
    "#valid_data, _ = random_split(valid_data, [train_size, val_size])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# split into text (input) and labels (output)\n",
    "train_texts, train_imgs, train_labels = list(zip(*map(lambda d: (d['text'], d['img'], d['label']), train_data)))\n",
    "valid_texts, valid_imgs, valid_labels = list(zip(*map(lambda d: (d['text'], d['img'], d['label']), valid_data)))\n",
    "\n",
    "len(train_texts), len(train_labels), len(valid_texts), len(valid_labels)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class imbalance\n",
    "print(sum(train_labels)/ len(train_labels))\n",
    "print(sum(valid_labels)/ len(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# analysis of review length\n",
    "sentences = [len(sent) for sent in train_texts]\n",
    "plt.rcParams.update({'figure.figsize':(7,5), 'figure.dpi':100})\n",
    "plt.bar(range(1,len(train_texts)+1), sentences, color = ['red'])\n",
    "plt.gca().set(title='No. of characters in each sentence', xlabel='Number of sentence', ylabel='Number of Characters in each sentence');\n",
    "\n",
    "# -> bert with 64 tokens should be sufficient"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# token embeddings with required separation token\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:62] + ['[SEP]'], train_texts))\n",
    "valid_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:62] + ['[SEP]'], valid_texts))\n",
    "\n",
    "len(train_tokens), len(valid_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# to be deleted -> SYNONYMES\n",
    "print(train_tokens[0])\n",
    "synonyme_idx = np.unique(np.random.randint(1, train_tokens[0].index('[SEP]'), int(0.2*train_tokens[0].index('[SEP]'))))\n",
    "print([train_tokens[0][idx] for idx in synonyme_idx])\n",
    "# remove stopwords and punctation\n",
    "synonyme_idx = [idx for idx in synonyme_idx if not train_tokens[0][idx] in stopwords.words()]\n",
    "synonyme_idx = [idx for idx in synonyme_idx if train_tokens[0][idx].isalnum()]\n",
    "\n",
    "# find synonyms of words to be masked\n",
    "replace_words = [train_tokens[0][idx] for idx in synonyme_idx] # don't use stopwords\n",
    "\n",
    "\n",
    "print(replace_words)\n",
    "synonymes = [wordnet.synsets(word) for word in replace_words]\n",
    "synonyme_idx = [synonyme_idx[i] for i in range(len(synonymes)) if synonymes[i]!=[]]\n",
    "synonymes = [synonymes[i] for i in range(len(synonymes)) if synonymes[i]!=[]]\n",
    "print(synonyme_idx)\n",
    "\n",
    "# replace words by synonyms\n",
    "for i_syn, i_sen in enumerate(synonyme_idx):\n",
    "    train_tokens[0][i_sen] = np.random.choice(synonymes[i_syn]).lemmas()[0].name()\n",
    "\n",
    "print(train_tokens[0])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything back into a dictionary\n",
    "data_train = {'img_names': train_imgs, 'tokens': train_tokens, 'labels': train_labels}\n",
    "\n",
    "data_valid = {'img_names': valid_imgs, 'tokens': valid_tokens, 'labels': valid_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "class HatefulMemesDataset(Dataset):\n",
    "    \"\"\" Hateful Memes dataset \"\"\"\n",
    "    \n",
    "    def __init__(self, data, img_dir, normalize=False, synonyme=False, transform=None):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df_path (string): path to jsonl file with image id's\n",
    "            root_dir (string): directory with all the images\n",
    "            transform (callable): optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        # text\n",
    "        self.data = data\n",
    "        \n",
    "        # image\n",
    "        self.img_dir = img_dir\n",
    "        self.normalize = normalize\n",
    "        self.transform = transform\n",
    "        self.synonyme = synonyme\n",
    "        \n",
    "    def __len__(self):\n",
    "        return len(self.data['labels'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx_tolist()\n",
    "            \n",
    "            \n",
    "        data_train = {'img_names': train_imgs, 'tokens': train_tokens, 'labels': train_labels}\n",
    "        \n",
    "        # load image ------------------------------------\n",
    "        img_name = os.path.join(self.img_dir, str(self.data['img_names'][idx]))\n",
    "        image = cv2.imread(img_name)\n",
    "        #image = image.astype(np.float)\n",
    "        \n",
    "        if self.normalize:\n",
    "            # TODO: normalize image by mean and std -> what data type do networks require?\n",
    "            print('TODO')\n",
    "        \n",
    "        # label ------------------------------------------\n",
    "        label = self.data['labels'][idx]\n",
    "        label = np.array([label])\n",
    "        label = label.astype('int').reshape(-1)\n",
    "        \n",
    "        # token -------------------------------------------\n",
    "        token = self.data['tokens'][idx]\n",
    "        \n",
    "        # add variance by synonyms\n",
    "        if self.synonyme:\n",
    "            synonyme_idx = np.unique(np.random.randint(1, token.index('[SEP]'), int(0.1*token.index('[SEP]'))))\n",
    "            # remove stopwords and punctation\n",
    "            synonyme_idx = [idx for idx in synonyme_idx if not token[idx] in stopwords.words()]\n",
    "            synonyme_idx = [idx for idx in synonyme_idx if token[idx].isalnum()]\n",
    "\n",
    "            # find synonyms of words to be masked\n",
    "            replace_words = [token[idx] for idx in synonyme_idx] # don't use stopwords\n",
    "            synonymes = [wordnet.synsets(word) for word in replace_words]\n",
    "            synonyme_idx = [synonyme_idx[i] for i in range(len(synonymes)) if synonymes[i]!=[]]\n",
    "            synonymes = [synonymes[i] for i in range(len(synonymes)) if synonymes[i]!=[]]\n",
    "\n",
    "            # replace words by synonyms\n",
    "            for i_syn, i_sen in enumerate(synonyme_idx):\n",
    "                token[i_sen:i_sen+1] = tokenizer.tokenize(np.random.choice(synonymes[i_syn]).lemmas()[0].name())\n",
    "        \n",
    "        # prepare token ids: each token (word fragment) corresponds to an id in the bert corpus\n",
    "        # further need to make all review the same length -> padding too short, truncating too long ones\n",
    "        token_id = pad_sequences([tokenizer.convert_tokens_to_ids(token)], maxlen=64, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "        token_id = token_id.reshape(-1)\n",
    "        \n",
    "        # mask for padding -> required by bert\n",
    "        mask = [float(i > 0) for i in token_id]\n",
    "        mask = np.array([mask])\n",
    "        mask = mask.astype('float').reshape(-1)\n",
    "        \n",
    "        #\n",
    "        sample = {'image': image, 'token_id': token_id, 'mask': mask, 'label': label}\n",
    "        \n",
    "        if self.transform:\n",
    "            sample = self.transform(sample)\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes_dataset = HatefulMemesDataset(data_train, img_dir='../data', normalize=False)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "\n",
    "for i in range(len(memes_dataset)):\n",
    "    sample = memes_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].shape, sample['label'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    #ax.set_xlabel(sample['text'])\n",
    "    #print(sample['token'])\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.imshow(sample['image'])\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "memes_dataset = HatefulMemesDataset(data_train, img_dir='../data', synonyme=True, normalize=False)\n",
    "\n",
    "fig = plt.figure(figsize=(16, 4))\n",
    "\n",
    "for i in range(len(memes_dataset)):\n",
    "    sample = memes_dataset[i]\n",
    "\n",
    "    print(i, sample['image'].shape, sample['label'].shape)\n",
    "\n",
    "    ax = plt.subplot(1, 4, i + 1)\n",
    "    plt.tight_layout()\n",
    "    ax.set_title('Sample #{}'.format(i))\n",
    "    #ax.set_xlabel(sample['text'])\n",
    "    #print(sample['token'])\n",
    "    ax.axis('off')\n",
    "    \n",
    "    plt.imshow(sample['image'])\n",
    "\n",
    "    if i == 3:\n",
    "        plt.show()\n",
    "        break"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Image augmentation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# aspect ratio = 1.3 (width / height) median\n",
    "# image dimensions = 128 x 128 (16k pixels) for CNN's\n",
    "\n",
    "class Rescale(object):\n",
    "    \"\"\"Rescale the image in a sample to a given size\n",
    "    Args:\n",
    "        img_width (int): desired width of image\n",
    "        max_distortion (float): maximum distortion of an image in a given direction\n",
    "    \"\"\"\n",
    "    \n",
    "    def __init__(self, size, max_distortion):\n",
    "        self.size = size\n",
    "        self.max_distortion = max_distortion\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, token_id, mask, label = sample['image'], sample['token_id'], sample['mask'], sample['label']\n",
    "\n",
    "        #\n",
    "        width, height = image.shape[:2]\n",
    "        aspect_ratio = width/ height\n",
    "        \n",
    "        # resulting distortion too high -> padding\n",
    "        if aspect_ratio > self.max_distortion:\n",
    "            pad = width- 2*height\n",
    "            img = cv2.copyMakeBorder(image, int(pad/2.), int(pad/2.), 0, 0, cv2.BORDER_CONSTANT)\n",
    "        elif 1./aspect_ratio > self.max_distortion:\n",
    "            pad = height- 2*width\n",
    "            img = cv2.copyMakeBorder(image, 0, 0, int(pad/2.), int(pad/2.), cv2.BORDER_CONSTANT)\n",
    "        else:\n",
    "            img = image.copy()\n",
    "            \n",
    "        # resize image\n",
    "        #img = img.astype(np.float)\n",
    "        img = transform.resize(img, (self.size, self.size))\n",
    "        \n",
    "        return {'image': img, 'token_id': token_id, 'mask': mask, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# cropping, scaling, rotation, noise, color?\n",
    "class Transform(object):\n",
    "    \"\"\"Crop randomly the image in a sample.\n",
    "\n",
    "    Args:\n",
    "        output_size (tuple or int): Desired output size. If int, square crop\n",
    "            is made.\n",
    "    \"\"\"\n",
    "\n",
    "    def __init__(self):\n",
    "        pass\n",
    "        \n",
    "    def __call__(self, sample):\n",
    "        image, token_id, mask, label = sample['image'], sample['token_id'], sample['mask'], sample['label']\n",
    "        \n",
    "        transform = transforms.Compose([transforms.ToPILImage(),\n",
    "                                        transforms.RandomRotation(degrees=(-20, 20))])\n",
    "        \n",
    "        # TODO: these lines needed?\n",
    "        img = (255.* image).astype(np.uint8)\n",
    "        img = transform(img.astype(np.uint8))\n",
    "        \n",
    "        \n",
    "        # TODO: use normalization as required by pretrained models\n",
    "        normalize = transforms.Normalize(mean=[0.485, 0.456, 0.406],\n",
    "                                         std=[0.229, 0.224, 0.225])\n",
    "        \n",
    "        \n",
    "        return {'image': img,'token_id': token_id, 'mask': mask, 'label': label}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "# dataset\n",
    "composed = transforms.Compose([Rescale(224, 2.),\n",
    "                               Transform()])\n",
    "\n",
    "memes_dataset = HatefulMemesDataset(data_train, img_dir='../data',\n",
    "                                    normalize=False, transform=composed)\n",
    "\n",
    "#plots\n",
    "ncols = 7\n",
    "nrows = 8\n",
    "fig, ax = plt.subplots(figsize=(16, 16), ncols=ncols, nrows=nrows)\n",
    "\n",
    "for i in range(ncols*nrows):\n",
    "    x = i%ncols \n",
    "    y = int(i/ncols)\n",
    "    \n",
    "    sample = memes_dataset[i]\n",
    "\n",
    "    ax[y,x].imshow(sample['image'])\n",
    "    ax[y,x].set_title('Sample #{}'.format(i))\n",
    "    ax[y,x].axis('off')\n",
    "\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert model class\n",
    "class BertBinaryClassifier(nn.Module):\n",
    "    def __init__(self, dropout=0.1):\n",
    "        super(BertBinaryClassifier, self).__init__()\n",
    "\n",
    "        self.bert = DistilBertModel.from_pretrained('distilbert-base-cased')#BertModel.from_pretrained('bert-base-uncased')\n",
    "\n",
    "        self.dropout = nn.Dropout(dropout)\n",
    "        self.linear = nn.Linear(768, 1)\n",
    "        self.sigmoid = nn.Sigmoid()\n",
    "    \n",
    "    def forward(self, imgs, tokens, masks=None):\n",
    "        _, pooled_output = self.bert(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        dropout_output = self.dropout(pooled_output)\n",
    "        linear_output = self.linear(dropout_output)\n",
    "        proba = self.sigmoid(linear_output)\n",
    "        return proba\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/combining-trained-models-in-pytorch/28383/2\n",
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        # pretrained models\n",
    "        self.modelVision = models.densenet121(pretrained=True)\n",
    "        self.modelNLP = BertModel.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        # freeze weights\n",
    "        for param in self.modelNLP.parameters():\n",
    "            param.requires_grad = False\n",
    "            \n",
    "        for param in self.modelVision.features.parameters():\n",
    "            param.requires_grad = False\n",
    "        \n",
    "        # give densenet an untrained classifier layer\n",
    "        self.modelVision.classifier = nn.Linear(1024, 1000)\n",
    "        \n",
    "        # classifier layer\n",
    "        self.dropout1 = torch.nn.Dropout(p=0.2)\n",
    "        self.layernorm1 = torch.nn.LayerNorm(768+1000)\n",
    "        self.classifier1 = nn.Linear(768+ 1000, 1000)\n",
    "        self.dropout2 = torch.nn.Dropout(p=0.2)\n",
    "        self.layernorm2 = torch.nn.LayerNorm(1000)\n",
    "        self.classifier2 = nn.Linear(1000, 1)\n",
    "        \n",
    "    def forward(self, imgs, tokens, masks):\n",
    "        # vision\n",
    "        x1 = F.relu(self.modelVision(imgs)) # to complete the new classifier layer with a nonlinearity\n",
    "        \n",
    "        # Bert is such that the first token contains all info for classification\n",
    "        _, x2 = self.modelNLP(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        \n",
    "        # TODO: dropout needed?\n",
    "        x = torch.cat((x1, x2), dim=1)\n",
    "        x = self.layernorm1(x)\n",
    "        x = F.relu(self.classifier1(x))\n",
    "        x = self.layernorm2(x)\n",
    "        y = torch.sigmoid(self.classifier2(x))\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# allocate on gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = MyEnsemble().to(device)\n",
    "print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
    "\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "# TODO: not sure if this does what I think it should do\n",
    "# optimizer\n",
    "param_optimizer = list(model.modelVision.classifier.named_parameters())\n",
    "param_optimizer += list(model.classifier1.named_parameters())\n",
    "param_optimizer += list(model.classifier2.named_parameters())\n",
    "optimizer_grouped_parameters = [{\"params\": [p for n, p in param_optimizer]}]\n",
    "\n",
    "lr = 1e-4\n",
    "optimizer = Adam(model.parameters(), lr=lr) # TODO: SGD for just the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print([p[1].size() for p in param_optimizer])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "densenet = models.densenet121(pretrained=True)\n",
    "for name, child in densenet.named_children():\n",
    "    print(name)\n",
    "    for param in child.parameters():\n",
    "            print(param.shape)\n",
    "print(sum(p.numel() for p in densenet.parameters()))\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "'''\n",
    "bert = BertModel.from_pretrained('bert-base-uncased')\n",
    "for name, child in bert.named_children():\n",
    "    print(name)\n",
    "    for param in child.parameters():\n",
    "            print(param.shape)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "        \n",
    "    if weights is not None:        \n",
    "        # TODO: should work since target = {0, 1}, thus sets weights to zero if not needed\n",
    "        loss = weights * (target * torch.log(output)) + \\\n",
    "               weights * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "\n",
    "    return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "# summary writer\n",
    "log_dir = './summaries/summary'+ date.today().strftime('%H-%d-%m-%Y')\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# training\n",
    "torch.cuda.empty_cache()   # Clearing Cache space for a fresh Model run\n",
    "\n",
    "EPOCHS=14\n",
    "BATCH_SIZE_TRAIN=8 # 4 if grad for all paramters\n",
    "BATCH_SIZE_VALID=4\n",
    "\n",
    "# training\n",
    "train_dataset = HatefulMemesDataset(data_train, img_dir='../data',\n",
    "                                    normalize=False, synonyme=True, transform=Rescale(224, 2.))\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, num_workers=1, shuffle=True)\n",
    "\n",
    "# validation\n",
    "valid_dataset = HatefulMemesDataset(data_valid, img_dir='../data',\n",
    "                                    normalize=False, transform=Rescale(224, 2.))\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE_VALID, shuffle=False)\n",
    "\n",
    "# binary cross entropy loss (classification)\n",
    "loss_func = nn.BCELoss()\n",
    "\n",
    "# monitor train progress\n",
    "stats = {'train_loss': [], 'train_acc': [], 'valid_loss': [], 'valid_acc': [], 'val_rocauc': []}\n",
    "\n",
    "time_tot = []\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    #\n",
    "    train_loss = 0.\n",
    "    train_correct = 0.\n",
    "    \n",
    "    valid_loss = 0.\n",
    "    valid_correct = 0.\n",
    "    \n",
    "    # training\n",
    "    model.train()\n",
    "    \n",
    "    # unfreeze weights\n",
    "    if epoch_num > EPOCHS -3:\n",
    "        for param in model.modelNLP.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        for param in model.modelVision.features.parameters():\n",
    "            param.requires_grad = True\n",
    "            \n",
    "        # Not sure if this is necessary (at least should not be harmful)\n",
    "        optimizer = Adam(model.parameters(), lr=lr)\n",
    "        \n",
    "        # not so elegant, but allows to first use a larger batch size\n",
    "        #lr = 3e-6\n",
    "        BATCH_SIZE_TRAIN=4\n",
    "        train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, num_workers=1, shuffle=True)\n",
    "\n",
    "        \n",
    "    for step_num, batch in enumerate(train_loader):\n",
    "        \n",
    "        # sample = {'image': image, 'token_id': token_id, 'mask': mask, 'label': label}        \n",
    "        imgs = batch['image'].to(device)\n",
    "        imgs = imgs.view(-1, 3, 224, 224)\n",
    "        \n",
    "        labels = batch['label'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "        token_ids = batch['token_id'].to(device)\n",
    "        # imgs, token_ids, masks, labels = tuple(t.to(device) for t in batch)\n",
    "        # print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
    "        \n",
    "        logits = model(imgs.float(), token_ids, masks)\n",
    "        \n",
    "        # account for class imbalance (66% label 0, 33% label 1)\n",
    "        eye = torch.ones(labels.shape, device=device)\n",
    "        weight_imbalance = (eye+ (labels==eye).int())* 0.63\n",
    "   \n",
    "        # loss\n",
    "        batch_loss = weighted_binary_cross_entropy(logits, labels.float(), weight_imbalance)\n",
    "        train_loss += batch_loss.item()\n",
    "        \n",
    "        train_correct += sum((torch.round(logits)==labels)*weight_imbalance).item()\n",
    "        \n",
    "        # reset gradient and calculate new ones\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # gradient clipping and backward pass\n",
    "        #clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # logging\n",
    "        # clear_output(wait=True) -> from IPython.display import clear_output\n",
    "        if step_num%100==0 and step_num> 0:\n",
    "            print('Epoch: ', epoch_num + 1)\n",
    "            print(\"\\r\" + \"{0}/{1} loss: {2} acc: {3} \".format(step_num,\n",
    "                                                              len(train_data) / BATCH_SIZE_TRAIN,\n",
    "                                                              round(train_loss / (step_num + 1), 3),\n",
    "                                                              round(train_correct/ ((step_num+1)* BATCH_SIZE_TRAIN), 3)))\n",
    "    \n",
    "    # train stats\n",
    "    stats['train_loss'].append(train_loss / ((step_num+1)* BATCH_SIZE_TRAIN))\n",
    "    stats['train_acc'].append(train_correct / ((step_num+1)* BATCH_SIZE_TRAIN))\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss / ((step_num+1)* BATCH_SIZE_TRAIN), epoch_num)\n",
    "    writer.add_scalar('Accuracy/train', train_correct / ((step_num+1)* BATCH_SIZE_TRAIN), epoch_num)\n",
    "    \n",
    "    # validation\n",
    "    torch.cuda.empty_cache()\n",
    "    model.eval()\n",
    "    \n",
    "    # TODO to calculate metrics\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    weight = []\n",
    "\n",
    "    for step_num, batch in enumerate(valid_loader):\n",
    "        # sample = {'image': image, 'token_id': token_id, 'mask': mask, 'label': label}        \n",
    "        imgs = batch['image'].to(device)\n",
    "        imgs = imgs.view(-1, 3, 224, 224)\n",
    "\n",
    "        labels = batch['label'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "        token_ids = batch['token_id'].to(device)\n",
    "\n",
    "        # account for class imbalance (66% label 0, 33% label 1)\n",
    "        eye = torch.ones(labels.shape, device=device)\n",
    "        weight_imbalance = (eye+ (labels==eye).int())* 0.63\n",
    "        \n",
    "        # loss\n",
    "        logits = model(imgs.float(), token_ids, masks)\n",
    "\n",
    "        batch_loss = weighted_binary_cross_entropy(logits, labels.float(), weight_imbalance)\n",
    "        valid_loss += batch_loss.item()\n",
    "        \n",
    "        valid_correct += sum((torch.round(logits)==labels)*weight_imbalance).item()\n",
    "        \n",
    "        # ROC AUC\n",
    "        ypred += logits.cpu().detach().numpy().reshape(-1).tolist()\n",
    "        \n",
    "        ytrue += labels.cpu().detach().numpy().reshape(-1).tolist()\n",
    "        weight += weight_imbalance.cpu().detach().numpy().reshape(-1).tolist()\n",
    "\n",
    "    # logging\n",
    "    # clear_output(wait=True) -> from IPython.display import clear_output\n",
    "    print('Epoch: ', epoch_num + 1)\n",
    "    print(\"\\r\" + \"Validation loss: {0} acc: {1} \".format(round(valid_loss / ((step_num+1)* BATCH_SIZE_VALID), 3),\n",
    "                                                         round(valid_correct/ ((step_num+1)* BATCH_SIZE_VALID), 3)))\n",
    "\n",
    "    # valid stats\n",
    "    stats['valid_loss'].append(valid_loss / ((step_num+1)* BATCH_SIZE_VALID))\n",
    "    stats['valid_acc'].append(valid_correct / ((step_num+1)* BATCH_SIZE_VALID))\n",
    "    stats['val_rocauc'].append(roc_auc_score(ytrue, ypred, average='weighted', sample_weight=weight))\n",
    "    \n",
    "    writer.add_scalar('Loss/valid', valid_loss / ((step_num+1)* BATCH_SIZE_VALID), epoch_num)\n",
    "    writer.add_scalar('Accuracy/valid', valid_correct / ((step_num+1)* BATCH_SIZE_VALID), epoch_num)\n",
    "    writer.add_scalar('ROCAUC/valid', roc_auc_score(ytrue, ypred, average='weighted', sample_weight=weight), epoch_num)\n",
    "    \n",
    "    # optimizer lr decay\n",
    "    lr*= 0.9\n",
    "    optimizer = Adam(model.parameters(), lr=lr)\n",
    "    \n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": true
   },
   "outputs": [],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4), ncols=3)\n",
    "ax[0].plot(stats['train_loss'])\n",
    "ax[0].plot(stats['valid_loss'])\n",
    "ax[0].legend(['train', 'valid'])\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "ax[1].plot(stats['train_acc'])\n",
    "ax[1].plot(stats['valid_acc'])\n",
    "ax[1].legend(['train', 'valid'])\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "\n",
    "ax[2].plot(stats['val_rocauc'])\n",
    "ax[2].legend(['valid'])\n",
    "ax[2].set_ylabel('ROC AUC')\n",
    "\n",
    "plt.savefig('../classifier_11_10.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "asdfsd"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import confusion_matrix\n",
    "from sklearn.metrics import plot_confusion_matrix\n",
    "\n",
    "conf_matr = confusion_matrix(ytrue, np.round(np.asarray(ypred)), sample_weight=weight)\n",
    "\n",
    "# predicted / True\n",
    "print(conf_matr.astype('int'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# loader\n",
    "valid_dataset = HatefulMemesDataset(data_valid, img_dir='../data',\n",
    "                                    normalize=False, transform=Rescale(224, 2.))\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE_VALID, shuffle=False)\n",
    "\n",
    "# TODO to calculate metrics\n",
    "ypred = []\n",
    "ytrue = []\n",
    "weight = []\n",
    "\n",
    "for step_num, batch in enumerate(valid_loader):\n",
    "    # sample = {'image': image, 'token_id': token_id, 'mask': mask, 'label': label}        \n",
    "    imgs = batch['image'].to(device)\n",
    "    imgs = imgs.view(-1, 3, 224, 224)\n",
    "\n",
    "    labels = batch['label'].to(device)\n",
    "    masks = batch['mask'].to(device)\n",
    "    token_ids = batch['token_id'].to(device)\n",
    "\n",
    "    # account for class imbalance (66% label 0, 33% label 1)\n",
    "    eye = torch.ones(labels.shape, device=device)\n",
    "    weight_imbalance = (eye+ (labels==eye).int())* 0.63\n",
    "\n",
    "    # loss\n",
    "    logits = model(imgs.float(), token_ids, masks)\n",
    "\n",
    "    batch_loss = weighted_binary_cross_entropy(logits, labels.float(), weight_imbalance)\n",
    "    valid_loss += batch_loss.item()\n",
    "\n",
    "    valid_correct += sum((torch.round(logits)==labels)*weight_imbalance).item()\n",
    "\n",
    "    # ROC AUC\n",
    "    ypred += logits.cpu().detach().numpy().reshape(-1).tolist()\n",
    "    ytrue += labels.cpu().detach().numpy().reshape(-1).tolist()\n",
    "    weight += weight_imbalance.cpu().detach().numpy().reshape(-1).tolist()\n",
    "    \n",
    "    #plots\n",
    "    for i in range(BATCH_SIZE_VALID):\n",
    "        if labels[i].item() != int(logits[i].item()):\n",
    "            plt.figure()\n",
    "            \n",
    "            print(imgs[i].cpu().shape)\n",
    "            plt.imshow(imgs[i].cpu().reshape(224,224,-1), cmap='gray')\n",
    "            plt.title('Label '+ str(labels[i].cpu().item())+ ' Predicted '+ str(int(logits[i])))\n",
    "            plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import roc_curve\n",
    "\n",
    "lr_fpr, lr_tpr, _ = roc_curve(ytrue, ypred)\n",
    "# plot the roc curve for the model\n",
    "plt.figure()\n",
    "plt.plot(lr_fpr, lr_tpr, marker='.', label='Logistic')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Predictions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# test data for competition\n",
    "path_test = '../data/test.jsonl'\n",
    "\n",
    "# read text\n",
    "dataset_test = pd.read_json(path_test, lines=True)\n",
    "\n",
    "# dictionary\n",
    "data_test = dataset_test.to_dict(orient='records') # have been shuffled in previous step\n",
    "\n",
    "# split into text (input) and labels (output)\n",
    "test_texts, test_imgs, test_ids = list(zip(*map(lambda d: (d['text'], d['img'], d['id']), data_test)))\n",
    "test_labels = np.zeros(len(test_ids)) # TODO: hack to use current implementation of Dataset class\n",
    "\n",
    "print(len(test_texts))\n",
    "\n",
    "# token embeddings with required separation token\n",
    "test_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:62] + ['[SEP]'], test_texts))\n",
    "\n",
    "# prepare token ids\n",
    "test_tokens_ids = pad_sequences(list(map(tokenizer.convert_tokens_to_ids, test_tokens)), maxlen=64, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "\n",
    "# mask for padding -> required by bert\n",
    "test_masks = [[float(i > 0) for i in ii] for ii in test_tokens_ids]\n",
    "\n",
    "# put everything back into a dictionary\n",
    "data_test = {'img_names': test_imgs, 'tokens': test_tokens, 'token_ids': test_tokens_ids,\n",
    "              'masks': test_masks, 'labels': test_labels}\n",
    "\n",
    "\n",
    "# test\n",
    "test_dataset = HatefulMemesDataset(data_test, img_dir='../data',\n",
    "                                    normalize=False, transform=Rescale(224, 2.)) # TODO: I somehwere read that image models need 224x224 input\n",
    "test_loader = torch.utils.data.DataLoader(test_dataset, batch_size=BATCH_SIZE_VALID, shuffle=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(test_ids[0])\n",
    "#d4 = dict(d1, **d2)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# prepare hand-in dataframe\n",
    "proba = []\n",
    "label = []\n",
    "\n",
    "# validation\n",
    "model.eval()\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "for step_num, batch in enumerate(test_loader):\n",
    "    # sample = {'image': image, 'token_id': token_id, 'mask': mask, 'label': label}        \n",
    "    imgs = batch['image'].to(device)\n",
    "    imgs = imgs.view(-1, 3, 224, 224)\n",
    "\n",
    "    masks = batch['mask'].to(device)\n",
    "    token_ids = batch['token_id'].to(device)\n",
    "\n",
    "    logits = model(imgs.float(), token_ids, masks)\n",
    "\n",
    "    #\n",
    "    proba += logits.cpu().detach().numpy().reshape(-1).tolist()\n",
    "    label += torch.round(logits).cpu().detach().numpy().reshape(-1).tolist()\n",
    "    \n",
    "# \n",
    "#proba = np.round(np.asarray(proba), 2)\n",
    "label = (np.asarray(label)).astype(int)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#\n",
    "dictt = {'id': test_ids, 'proba': proba, 'label': label}\n",
    "\n",
    "df = pd.DataFrame(data=dictt)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(df)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "df.to_csv('../data/pred_10_10', index=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "nltk.download('wordnet')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = wordnet.synsets(\"program\")\n",
    "wordnet.synsets(\"program\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(syns)\n",
    "print(wordnet.synsets(\"program\")[np.random.randint(len(syns))].lemmas()[0].name())\n",
    "print(np.random.choice(wordnet.synsets(\"program\")).lemmas()[0].name())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "syns = wordnet.synsets(\"program\")\n",
    "print(syns)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "print(syns[0].lemmas())"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
