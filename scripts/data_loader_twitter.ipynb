{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "Using TensorFlow backend.\n"
     ]
    }
   ],
   "source": [
    "# general\n",
    "from __future__ import print_function, division\n",
    "import os\n",
    "import pandas as pd\n",
    "from skimage import io, transform\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "import cv2\n",
    "import random\n",
    "from datetime import datetime\n",
    "\n",
    "import GPUtil\n",
    "\n",
    "# torch\n",
    "import torch\n",
    "from torch.utils.data import Dataset, DataLoader\n",
    "from torchvision import transforms, utils\n",
    "from torch.utils.data import random_split\n",
    "\n",
    "from pytorch_pretrained_bert import BertTokenizer\n",
    "from keras.preprocessing.sequence import pad_sequences\n",
    "\n",
    "import torch.nn as nn\n",
    "import torchvision.models as models\n",
    "from pytorch_pretrained_bert import BertModel\n",
    "from transformers import DistilBertModel\n",
    "import torch.nn.functional as F\n",
    "\n",
    "import nltk\n",
    "from nltk.corpus import wordnet\n",
    "from nltk.corpus import stopwords"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Reproducibility\n",
    "random.seed(0)\n",
    "np.random.seed(0)\n",
    "torch.manual_seed(0)\n",
    "torch.cuda.manual_seed(0)\n",
    "torch.backends.cudnn.deterministic=True"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Structure\n",
    "- plot images\n",
    "- text preprocessing\n",
    "- data loader\n",
    "- image augmentation"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Text Preprocessing"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Bert requires: <br>\n",
    "- tokenization\n",
    "- special characters\n",
    "- padding\n",
    "- mask\n",
    "\n",
    "techniques to try (for other models): <br>\n",
    "- Lower casing\n",
    "- Punctuation removal\n",
    "- Stopwords removal\n",
    "- Frequent words removal\n",
    "- Rare words removal\n",
    "- Spelling correction\n",
    "- Tokenization\n",
    "- Stemming\n",
    "- Lemmatization\n",
    "- word embedding/ bag of words"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1    19190\n",
      "2     4163\n",
      "0     1430\n",
      "Name: class, dtype: int64\n",
      "2    4000\n",
      "1    4000\n",
      "0    1400\n",
      "Name: class, dtype: int64\n",
      "    class                                              tweet\n",
      "85      0  \"@Blackman38Tide: @WhaleLookyHere @HowdyDowdy1...\n",
      "90      0  \"@CB_Baby24: @white_thunduh alsarabsss\" hes a ...\n",
      "111     0  \"@DevilGrimz: @VigxRArts you're fucking gay, b...\n",
      "186     0  \"@MarkRoundtreeJr: LMFAOOOO I HATE BLACK PEOPL...\n",
      "204     0  \"@NoChillPaz: \"At least I'm not a nigger\" http...\n",
      "206     0  \"@NotoriousBM95: @_WhitePonyJr_ Ariza is a sna...\n",
      "221     0  \"@RTNBA: Drakes new shoes that will be release...\n",
      "263     0  \"@TheoMaxximus: #GerrysHalloweenParty http://t...\n",
      "317     0  \"@ashlingwilde: @ItsNotAdam is bored supposed ...\n",
      "320     0  \"@bigbootybishopp: @white_thunduh lassen cc , ...\n"
     ]
    }
   ],
   "source": [
    "df = pd.read_pickle('../data/labeled_data.p')\n",
    "\n",
    "# analyze imbalance\n",
    "print(df[\"class\"].value_counts())\n",
    "\n",
    "# drop class 1 for the first\n",
    "#df = df.drop(df[df['class'] == 1].index)\n",
    "df = df.drop(['count', 'hate_speech', 'offensive_language', 'neither'], axis=1)\n",
    "\n",
    "# convert class 2 -> 1 to be in accordance with standards\n",
    "'''\n",
    "def convert_standard(x):\n",
    "    return 0 if x == 0 else 1\n",
    "df['class'] = df['class'].apply(convert_standard) \n",
    "'''\n",
    "\n",
    "df0 = df.loc[df['class']==0]\n",
    "df1 = df.loc[df['class']==1]\n",
    "df2 = df.loc[df['class']==2]\n",
    "df = pd.concat([df0[:1400], df1[:4000], df2[:4000]])\n",
    "\n",
    "print(df[\"class\"].value_counts())\n",
    "\n",
    "print(df.head(10))\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "    class                                              tweet\n",
      "85      0                                       queer gaywad\n",
      "90      0  alsarabsss hes a beaner smh you can tell hes a...\n",
      "111     0  youre fucking gay blacklisted hoe holding out ...\n",
      "186     0                       lmfaoooo i hate black people\n",
      "204     0                     at least im not a nigger lmfao\n"
     ]
    }
   ],
   "source": [
    "import re\n",
    "def preprocess(text):\n",
    "\n",
    "    text=text.lower()\n",
    "    # remove hyperlinks\n",
    "    text = re.sub(r'https?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    text = re.sub(r'http?:\\/\\/.*[\\r\\n]*', '', text)\n",
    "    #Replace &amp, &lt, &gt with &,<,> respectively\n",
    "    text=text.replace(r'&amp;?',r'and')\n",
    "    text=text.replace(r'&lt;',r'<')\n",
    "    text=text.replace(r'&gt;',r'>')\n",
    "    #remove hashtag sign\n",
    "    #text=re.sub(r\"#\",\"\",text)   \n",
    "    #remove mentions\n",
    "    text = re.sub(r\"(?:\\@)\\w+\", '', text)\n",
    "    #text=re.sub(r\"@\",\"\",text)\n",
    "    #remove non ascii chars\n",
    "    text=text.encode(\"ascii\",errors=\"ignore\").decode()\n",
    "    #remove some puncts (except . ! ?)\n",
    "    text=re.sub(r'[:\"#$%&\\*+,-/:;<=>@\\\\^_`{|}~]+','',text)\n",
    "    text=re.sub(r'[!]+','!',text)\n",
    "    text=re.sub(r'[?]+','?',text)\n",
    "    text=re.sub(r'[.]+','.',text)\n",
    "    text=re.sub(r\"'\",\"\",text)\n",
    "    text=re.sub(r\"\\(\",\"\",text)\n",
    "    text=re.sub(r\"\\)\",\"\",text)\n",
    "    \n",
    "    text=\" \".join(text.split())\n",
    "    return text\n",
    "\n",
    "df['tweet'] = df['tweet'].apply(preprocess)\n",
    "df = df[df[\"tweet\"]!='']\n",
    "\n",
    "print(df.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "      class                                              tweet\n",
      "85        0                                       queer gaywad\n",
      "90        0  alsarabsss hes a beaner smh you can tell hes a...\n",
      "111       0  youre fucking gay blacklisted hoe holding out ...\n",
      "186       0                       lmfaoooo i hate black people\n",
      "204       0                     at least im not a nigger lmfao\n",
      "...     ...                                                ...\n",
      "24207     2  cheeky lol rt i want those all black and yello...\n",
      "24208     2                            chicken spaghetti trash\n",
      "24214     2  cleaned all the bird nests out of the downspou...\n",
      "24215     2                        colored denim makes me puke\n",
      "24216     2  cookies and crackers arent even on the same le...\n",
      "\n",
      "[9389 rows x 2 columns]\n",
      "1    3997\n",
      "2    3993\n",
      "0    1399\n",
      "Name: class, dtype: int64\n",
      "tensor([0.2058, 0.2061, 0.5881], dtype=torch.float64)\n"
     ]
    }
   ],
   "source": [
    "#dataset_df = pd.read_json('../data/train.jsonl', lines=True)\n",
    "\n",
    "# dictionary\n",
    "data = df.to_dict(orient='records') # have been shuffled in previous step\n",
    "\n",
    "print(df)\n",
    "\n",
    "# train valid split\n",
    "from sklearn.model_selection import train_test_split\n",
    "train_data, valid_data = train_test_split(data, test_size=0.20)\n",
    "#valid_data, _ = train_test_split(valid_data, test_size=0.9)\n",
    "\n",
    "\n",
    "wc = df['class'].value_counts()\n",
    "print(wc)\n",
    "wc = 1/wc/ sum(1/wc)\n",
    "weight_classes = torch.tensor(wc)\n",
    "print(weight_classes)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "# split into text (input) and labels (output)\n",
    "train_texts, train_labels = list(zip(*map(lambda d: (d['tweet'], d['class']), train_data)))\n",
    "valid_texts, valid_labels = list(zip(*map(lambda d: (d['tweet'], d['class']), valid_data)))\n",
    "\n",
    "len(train_texts), len(train_labels), len(valid_texts), len(valid_labels)\n",
    "\n",
    "train_texts_len = list(map(lambda t: len(t), train_texts))\n",
    "\n",
    "plt.figure()\n",
    "plt.hist(train_texts_len, bins=20)\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.2749301025163093\n",
      "1.2816826411075612\n"
     ]
    }
   ],
   "source": [
    "# class imbalance\n",
    "print(sum(train_labels)/ len(train_labels))\n",
    "print(sum(valid_labels)/ len(valid_labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "# bert tokenizer\n",
    "tokenizer = BertTokenizer.from_pretrained('bert-base-cased', do_lower_case=False)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(7511, 1878)"
      ]
     },
     "execution_count": 9,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# token embeddings with required separation token\n",
    "train_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:124] + ['[SEP]'], train_texts))\n",
    "valid_tokens = list(map(lambda t: ['[CLS]'] + tokenizer.tokenize(t)[:124] + ['[SEP]'], valid_texts))\n",
    "\n",
    "len(train_tokens), len(valid_tokens)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "# put everything back into a dictionary\n",
    "data_train = {'tokens': train_tokens, 'labels': train_labels}\n",
    "\n",
    "data_valid = {'tokens': valid_tokens, 'labels': valid_labels}"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Dataloader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "pretrained_dict = pretrained_model.state_dict()class HatefulMemesDataset(Dataset):\n",
    "    \"\"\" Hateful Memes dataset \"\"\"\n",
    "    \n",
    "    def __init__(self, data):\n",
    "        \"\"\"\n",
    "        Args:\n",
    "            df_path (string): path to jsonl file with image id's\n",
    "            root_dir (string): directory with all the images\n",
    "            transform (callable): optional transform to be applied on a sample\n",
    "        \"\"\"\n",
    "        # text\n",
    "        self.data = data\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.data['labels'])\n",
    "    \n",
    "    def __getitem__(self, idx):\n",
    "        if torch.is_tensor(idx):\n",
    "            idx = idx_tolist()\n",
    "            \n",
    "            \n",
    "        data_train = {'tokens': train_tokens, 'labels': train_labels}\n",
    "        \n",
    "        # label ------------------------------------------\n",
    "        label = self.data['labels'][idx]\n",
    "        label = np.array([label])\n",
    "        label = label.astype('int').reshape(-1)\n",
    "        \n",
    "        # token -------------------------------------------\n",
    "        token = self.data['tokens'][idx]\n",
    "\n",
    "        # prepare token ids: each token (word fragment) corresponds to an id in the bert corpus\n",
    "        # further need to make all review the same length -> padding too short, truncating too long ones\n",
    "        token_id = pad_sequences([tokenizer.convert_tokens_to_ids(token)], maxlen=126, truncating=\"post\", padding=\"post\", dtype=\"int\")\n",
    "        token_id = token_id.reshape(-1)\n",
    "        \n",
    "        # mask for padding -> required by bert\n",
    "        mask = [float(i > 0) for i in token_id]\n",
    "        mask = np.array([mask])\n",
    "        mask = mask.astype('float').reshape(-1)\n",
    "        \n",
    "        #\n",
    "        sample = {'token_id': token_id, 'mask': mask, 'label': label}\n",
    "            \n",
    "        return sample"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Model "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "# https://discuss.pytorch.org/t/combining-trained-models-in-pytorch/28383/2\n",
    "class MyEnsemble(nn.Module):\n",
    "    def __init__(self):\n",
    "        super(MyEnsemble, self).__init__()\n",
    "        # pretrained models\n",
    "        self.modelNLP = BertModel.from_pretrained('bert-base-cased')\n",
    "        \n",
    "        # classifier layer\n",
    "        #self.layernorm1 = torch.nn.LayerNorm(768)\n",
    "        self.classifier1 = nn.Linear(768, 3)\n",
    "        self.dropout = torch.nn.Dropout(p=0.5)\n",
    "        \n",
    "    def forward(self, tokens, masks):\n",
    "        # Bert is such that the first token contains all info for classification\n",
    "        _, x2 = self.modelNLP(tokens, attention_mask=masks, output_all_encoded_layers=False)\n",
    "        #x = self.layernorm1(x2)\n",
    "        x = self.dropout(x2)\n",
    "        y = self.classifier1(x)\n",
    "        \n",
    "        return y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "model = MyEnsemble()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "modelNLP.embeddings.word_embeddings.weight\n",
      "modelNLP.embeddings.position_embeddings.weight\n",
      "modelNLP.embeddings.token_type_embeddings.weight\n",
      "modelNLP.embeddings.LayerNorm.weight\n",
      "modelNLP.embeddings.LayerNorm.bias\n",
      "modelNLP.encoder.layer.0.attention.self.query.weight\n",
      "modelNLP.encoder.layer.0.attention.self.query.bias\n",
      "modelNLP.encoder.layer.0.attention.self.key.weight\n",
      "modelNLP.encoder.layer.0.attention.self.key.bias\n",
      "modelNLP.encoder.layer.0.attention.self.value.weight\n",
      "modelNLP.encoder.layer.0.attention.self.value.bias\n",
      "modelNLP.encoder.layer.0.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.0.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.0.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.0.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.0.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.0.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.0.output.dense.weight\n",
      "modelNLP.encoder.layer.0.output.dense.bias\n",
      "modelNLP.encoder.layer.0.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.0.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.1.attention.self.query.weight\n",
      "modelNLP.encoder.layer.1.attention.self.query.bias\n",
      "modelNLP.encoder.layer.1.attention.self.key.weight\n",
      "modelNLP.encoder.layer.1.attention.self.key.bias\n",
      "modelNLP.encoder.layer.1.attention.self.value.weight\n",
      "modelNLP.encoder.layer.1.attention.self.value.bias\n",
      "modelNLP.encoder.layer.1.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.1.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.1.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.1.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.1.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.1.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.1.output.dense.weight\n",
      "modelNLP.encoder.layer.1.output.dense.bias\n",
      "modelNLP.encoder.layer.1.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.1.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.2.attention.self.query.weight\n",
      "modelNLP.encoder.layer.2.attention.self.query.bias\n",
      "modelNLP.encoder.layer.2.attention.self.key.weight\n",
      "modelNLP.encoder.layer.2.attention.self.key.bias\n",
      "modelNLP.encoder.layer.2.attention.self.value.weight\n",
      "modelNLP.encoder.layer.2.attention.self.value.bias\n",
      "modelNLP.encoder.layer.2.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.2.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.2.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.2.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.2.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.2.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.2.output.dense.weight\n",
      "modelNLP.encoder.layer.2.output.dense.bias\n",
      "modelNLP.encoder.layer.2.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.2.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.3.attention.self.query.weight\n",
      "modelNLP.encoder.layer.3.attention.self.query.bias\n",
      "modelNLP.encoder.layer.3.attention.self.key.weight\n",
      "modelNLP.encoder.layer.3.attention.self.key.bias\n",
      "modelNLP.encoder.layer.3.attention.self.value.weight\n",
      "modelNLP.encoder.layer.3.attention.self.value.bias\n",
      "modelNLP.encoder.layer.3.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.3.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.3.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.3.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.3.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.3.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.3.output.dense.weight\n",
      "modelNLP.encoder.layer.3.output.dense.bias\n",
      "modelNLP.encoder.layer.3.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.3.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.4.attention.self.query.weight\n",
      "modelNLP.encoder.layer.4.attention.self.query.bias\n",
      "modelNLP.encoder.layer.4.attention.self.key.weight\n",
      "modelNLP.encoder.layer.4.attention.self.key.bias\n",
      "modelNLP.encoder.layer.4.attention.self.value.weight\n",
      "modelNLP.encoder.layer.4.attention.self.value.bias\n",
      "modelNLP.encoder.layer.4.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.4.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.4.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.4.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.4.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.4.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.4.output.dense.weight\n",
      "modelNLP.encoder.layer.4.output.dense.bias\n",
      "modelNLP.encoder.layer.4.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.4.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.5.attention.self.query.weight\n",
      "modelNLP.encoder.layer.5.attention.self.query.bias\n",
      "modelNLP.encoder.layer.5.attention.self.key.weight\n",
      "modelNLP.encoder.layer.5.attention.self.key.bias\n",
      "modelNLP.encoder.layer.5.attention.self.value.weight\n",
      "modelNLP.encoder.layer.5.attention.self.value.bias\n",
      "modelNLP.encoder.layer.5.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.5.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.5.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.5.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.5.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.5.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.5.output.dense.weight\n",
      "modelNLP.encoder.layer.5.output.dense.bias\n",
      "modelNLP.encoder.layer.5.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.5.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.6.attention.self.query.weight\n",
      "modelNLP.encoder.layer.6.attention.self.query.bias\n",
      "modelNLP.encoder.layer.6.attention.self.key.weight\n",
      "modelNLP.encoder.layer.6.attention.self.key.bias\n",
      "modelNLP.encoder.layer.6.attention.self.value.weight\n",
      "modelNLP.encoder.layer.6.attention.self.value.bias\n",
      "modelNLP.encoder.layer.6.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.6.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.6.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.6.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.6.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.6.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.6.output.dense.weight\n",
      "modelNLP.encoder.layer.6.output.dense.bias\n",
      "modelNLP.encoder.layer.6.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.6.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.7.attention.self.query.weight\n",
      "modelNLP.encoder.layer.7.attention.self.query.bias\n",
      "modelNLP.encoder.layer.7.attention.self.key.weight\n",
      "modelNLP.encoder.layer.7.attention.self.key.bias\n",
      "modelNLP.encoder.layer.7.attention.self.value.weight\n",
      "modelNLP.encoder.layer.7.attention.self.value.bias\n",
      "modelNLP.encoder.layer.7.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.7.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.7.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.7.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.7.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.7.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.7.output.dense.weight\n",
      "modelNLP.encoder.layer.7.output.dense.bias\n",
      "modelNLP.encoder.layer.7.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.7.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.8.attention.self.query.weight\n",
      "modelNLP.encoder.layer.8.attention.self.query.bias\n",
      "modelNLP.encoder.layer.8.attention.self.key.weight\n",
      "modelNLP.encoder.layer.8.attention.self.key.bias\n",
      "modelNLP.encoder.layer.8.attention.self.value.weight\n",
      "modelNLP.encoder.layer.8.attention.self.value.bias\n",
      "modelNLP.encoder.layer.8.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.8.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.8.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.8.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.8.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.8.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.8.output.dense.weight\n",
      "modelNLP.encoder.layer.8.output.dense.bias\n",
      "modelNLP.encoder.layer.8.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.8.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.9.attention.self.query.weight\n",
      "modelNLP.encoder.layer.9.attention.self.query.bias\n",
      "modelNLP.encoder.layer.9.attention.self.key.weight\n",
      "modelNLP.encoder.layer.9.attention.self.key.bias\n",
      "modelNLP.encoder.layer.9.attention.self.value.weight\n",
      "modelNLP.encoder.layer.9.attention.self.value.bias\n",
      "modelNLP.encoder.layer.9.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.9.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.9.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.9.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.9.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.9.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.9.output.dense.weight\n",
      "modelNLP.encoder.layer.9.output.dense.bias\n",
      "modelNLP.encoder.layer.9.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.9.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.10.attention.self.query.weight\n",
      "modelNLP.encoder.layer.10.attention.self.query.bias\n",
      "modelNLP.encoder.layer.10.attention.self.key.weight\n",
      "modelNLP.encoder.layer.10.attention.self.key.bias\n",
      "modelNLP.encoder.layer.10.attention.self.value.weight\n",
      "modelNLP.encoder.layer.10.attention.self.value.bias\n",
      "modelNLP.encoder.layer.10.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.10.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.10.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.10.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.10.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.10.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.10.output.dense.weight\n",
      "modelNLP.encoder.layer.10.output.dense.bias\n",
      "modelNLP.encoder.layer.10.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.10.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.11.attention.self.query.weight\n",
      "modelNLP.encoder.layer.11.attention.self.query.bias\n",
      "modelNLP.encoder.layer.11.attention.self.key.weight\n",
      "modelNLP.encoder.layer.11.attention.self.key.bias\n",
      "modelNLP.encoder.layer.11.attention.self.value.weight\n",
      "modelNLP.encoder.layer.11.attention.self.value.bias\n",
      "modelNLP.encoder.layer.11.attention.output.dense.weight\n",
      "modelNLP.encoder.layer.11.attention.output.dense.bias\n",
      "modelNLP.encoder.layer.11.attention.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.11.attention.output.LayerNorm.bias\n",
      "modelNLP.encoder.layer.11.intermediate.dense.weight\n",
      "modelNLP.encoder.layer.11.intermediate.dense.bias\n",
      "modelNLP.encoder.layer.11.output.dense.weight\n",
      "modelNLP.encoder.layer.11.output.dense.bias\n",
      "modelNLP.encoder.layer.11.output.LayerNorm.weight\n",
      "modelNLP.encoder.layer.11.output.LayerNorm.bias\n",
      "modelNLP.pooler.dense.weight\n",
      "modelNLP.pooler.dense.bias\n",
      "layernorm1.weight\n",
      "layernorm1.bias\n",
      "classifier1.weight\n",
      "classifier1.bias\n"
     ]
    }
   ],
   "source": [
    "for name, param in model.named_parameters():\n",
    "    if param.requires_grad:\n",
    "        print(name)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "'\\n# Initialize model\\nmodel.apply(weight_init)\\nmodel_dict = model.state_dict()\\n\\n# Fiter out unneccessary keys\\nfiltered_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\\nmodel_dict.update(filtered_dict)\\nmodel.load_state_dict(model_dict)\\n'"
      ]
     },
     "execution_count": 15,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "'''\n",
    "# Initialize model\n",
    "model.apply(weight_init)\n",
    "model_dict = model.state_dict()\n",
    "\n",
    "# Fiter out unneccessary keys\n",
    "filtered_dict = {k: v for k, v in pretrained_dict.items() if k in model_dict}\n",
    "model_dict.update(filtered_dict)\n",
    "model.load_state_dict(model_dict)\n",
    "'''"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "433.781248M\n",
      "| ID | GPU | MEM |\n",
      "------------------\n",
      "|  0 |  8% | 23% |\n",
      "108314115\n",
      "108314115\n"
     ]
    }
   ],
   "source": [
    "# allocate on gpu\n",
    "os.environ[\"CUDA_VISIBLE_DEVICES\"] = '0'\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "torch.cuda.empty_cache()\n",
    "\n",
    "model = MyEnsemble().to(device)\n",
    "print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
    "\n",
    "GPUtil.showUtilization()\n",
    "\n",
    "print(sum(p.numel() for p in model.parameters()))\n",
    "print(sum(p.numel() for p in model.parameters() if p.requires_grad))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "metadata": {},
   "outputs": [],
   "source": [
    "from torch.optim import Adam\n",
    "# TODO: not sure if this does what I think it should do\n",
    "# optimizer\n",
    "lr = 5e-6\n",
    "optimizer = Adam(model.parameters(), lr=lr) # TODO: SGD for just the final classifier"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "metadata": {},
   "outputs": [],
   "source": [
    "def weighted_binary_cross_entropy(output, target, weights=None):\n",
    "        \n",
    "    if weights is not None:        \n",
    "        # TODO: should work since target = {0, 1}, thus sets weights to zero if not needed\n",
    "        loss = weights * (target * torch.log(output)) + \\\n",
    "               weights * ((1 - target) * torch.log(1 - output))\n",
    "    else:\n",
    "        loss = target * torch.log(output) + (1 - target) * torch.log(1 - output)\n",
    "\n",
    "    return torch.neg(torch.mean(loss))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import date\n",
    "# summary writer\n",
    "log_dir = './summaries/summary'+ date.today().strftime('%H-%d-%m-%Y')\n",
    "from torch.utils.tensorboard import SummaryWriter\n",
    "writer = SummaryWriter(log_dir)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Training"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 20,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch:  1\n",
      "50/938.875 loss: 2.774 acc: 0.322 \n",
      "Epoch:  1\n",
      "100/938.875 loss: 2.691 acc: 0.326 \n",
      "Epoch:  1\n",
      "150/938.875 loss: 2.598 acc: 0.337 \n",
      "Epoch:  1\n",
      "200/938.875 loss: 2.519 acc: 0.343 \n",
      "Epoch:  1\n",
      "250/938.875 loss: 2.467 acc: 0.349 \n",
      "Epoch:  1\n",
      "300/938.875 loss: 2.368 acc: 0.366 \n",
      "Epoch:  1\n",
      "350/938.875 loss: 2.277 acc: 0.381 \n",
      "Epoch:  1\n",
      "400/938.875 loss: 2.191 acc: 0.397 \n",
      "Epoch:  1\n",
      "450/938.875 loss: 2.115 acc: 0.416 \n",
      "Epoch:  1\n",
      "500/938.875 loss: 2.04 acc: 0.435 \n",
      "Epoch:  1\n",
      "550/938.875 loss: 1.968 acc: 0.452 \n",
      "Epoch:  1\n",
      "600/938.875 loss: 1.903 acc: 0.466 \n",
      "Epoch:  1\n",
      "650/938.875 loss: 1.858 acc: 0.477 \n",
      "Epoch:  1\n",
      "700/938.875 loss: 1.812 acc: 0.487 \n",
      "Epoch:  1\n",
      "750/938.875 loss: 1.764 acc: 0.497 \n",
      "Epoch:  1\n",
      "800/938.875 loss: 1.721 acc: 0.506 \n",
      "Epoch:  1\n",
      "850/938.875 loss: 1.688 acc: 0.513 \n",
      "Epoch:  1\n",
      "900/938.875 loss: 1.647 acc: 0.522 \n",
      "Epoch:  2\n",
      "50/938.875 loss: 0.885 acc: 0.755 \n",
      "Epoch:  2\n",
      "100/938.875 loss: 0.918 acc: 0.74 \n",
      "Epoch:  2\n",
      "150/938.875 loss: 0.907 acc: 0.741 \n",
      "Epoch:  2\n",
      "200/938.875 loss: 0.865 acc: 0.759 \n",
      "Epoch:  2\n",
      "250/938.875 loss: 0.84 acc: 0.757 \n",
      "Epoch:  2\n",
      "300/938.875 loss: 0.841 acc: 0.757 \n",
      "Epoch:  2\n",
      "350/938.875 loss: 0.869 acc: 0.766 \n",
      "Epoch:  2\n",
      "400/938.875 loss: 0.873 acc: 0.76 \n",
      "Epoch:  2\n",
      "450/938.875 loss: 0.862 acc: 0.762 \n",
      "Epoch:  2\n",
      "500/938.875 loss: 0.859 acc: 0.759 \n",
      "Epoch:  2\n",
      "550/938.875 loss: 0.861 acc: 0.758 \n",
      "Epoch:  2\n",
      "600/938.875 loss: 0.864 acc: 0.759 \n",
      "Epoch:  2\n",
      "650/938.875 loss: 0.85 acc: 0.759 \n",
      "Epoch:  2\n",
      "700/938.875 loss: 0.845 acc: 0.76 \n",
      "Epoch:  2\n",
      "750/938.875 loss: 0.837 acc: 0.76 \n",
      "Epoch:  2\n",
      "800/938.875 loss: 0.834 acc: 0.76 \n",
      "Epoch:  2\n",
      "850/938.875 loss: 0.829 acc: 0.765 \n",
      "Epoch:  2\n",
      "900/938.875 loss: 0.827 acc: 0.764 \n",
      "Epoch:  3\n",
      "50/938.875 loss: 0.666 acc: 0.81 \n",
      "Epoch:  3\n",
      "100/938.875 loss: 0.674 acc: 0.809 \n",
      "Epoch:  3\n",
      "150/938.875 loss: 0.659 acc: 0.811 \n",
      "Epoch:  3\n",
      "200/938.875 loss: 0.677 acc: 0.81 \n",
      "Epoch:  3\n",
      "250/938.875 loss: 0.658 acc: 0.812 \n",
      "Epoch:  3\n",
      "300/938.875 loss: 0.654 acc: 0.816 \n",
      "Epoch:  3\n",
      "350/938.875 loss: 0.662 acc: 0.817 \n",
      "Epoch:  3\n",
      "400/938.875 loss: 0.66 acc: 0.817 \n",
      "Epoch:  3\n",
      "450/938.875 loss: 0.67 acc: 0.817 \n",
      "Epoch:  3\n",
      "500/938.875 loss: 0.668 acc: 0.812 \n",
      "Epoch:  3\n",
      "550/938.875 loss: 0.656 acc: 0.816 \n",
      "Epoch:  3\n",
      "600/938.875 loss: 0.667 acc: 0.814 \n",
      "Epoch:  3\n",
      "650/938.875 loss: 0.672 acc: 0.811 \n",
      "Epoch:  3\n",
      "700/938.875 loss: 0.672 acc: 0.808 \n",
      "Epoch:  3\n",
      "750/938.875 loss: 0.676 acc: 0.805 \n",
      "Epoch:  3\n",
      "800/938.875 loss: 0.675 acc: 0.806 \n",
      "Epoch:  3\n",
      "850/938.875 loss: 0.675 acc: 0.807 \n",
      "Epoch:  3\n",
      "900/938.875 loss: 0.679 acc: 0.804 \n",
      "Epoch:  4\n",
      "50/938.875 loss: 0.556 acc: 0.849 \n",
      "Epoch:  4\n",
      "100/938.875 loss: 0.571 acc: 0.851 \n",
      "Epoch:  4\n",
      "150/938.875 loss: 0.533 acc: 0.847 \n",
      "Epoch:  4\n",
      "200/938.875 loss: 0.507 acc: 0.848 \n",
      "Epoch:  4\n",
      "250/938.875 loss: 0.518 acc: 0.843 \n",
      "Epoch:  4\n",
      "300/938.875 loss: 0.522 acc: 0.841 \n",
      "Epoch:  4\n",
      "350/938.875 loss: 0.512 acc: 0.844 \n",
      "Epoch:  4\n",
      "400/938.875 loss: 0.518 acc: 0.844 \n",
      "Epoch:  4\n",
      "450/938.875 loss: 0.518 acc: 0.839 \n",
      "Epoch:  4\n",
      "500/938.875 loss: 0.522 acc: 0.836 \n",
      "Epoch:  4\n",
      "550/938.875 loss: 0.533 acc: 0.836 \n",
      "Epoch:  4\n",
      "600/938.875 loss: 0.536 acc: 0.835 \n",
      "Epoch:  4\n",
      "650/938.875 loss: 0.531 acc: 0.835 \n",
      "Epoch:  4\n",
      "700/938.875 loss: 0.533 acc: 0.837 \n",
      "Epoch:  4\n",
      "750/938.875 loss: 0.53 acc: 0.84 \n",
      "Epoch:  4\n",
      "800/938.875 loss: 0.544 acc: 0.837 \n",
      "Epoch:  4\n",
      "850/938.875 loss: 0.535 acc: 0.837 \n",
      "Epoch:  4\n",
      "900/938.875 loss: 0.539 acc: 0.837 \n",
      "Epoch:  5\n",
      "50/938.875 loss: 0.412 acc: 0.881 \n",
      "Epoch:  5\n",
      "100/938.875 loss: 0.429 acc: 0.847 \n",
      "Epoch:  5\n",
      "150/938.875 loss: 0.414 acc: 0.869 \n",
      "Epoch:  5\n",
      "200/938.875 loss: 0.416 acc: 0.864 \n",
      "Epoch:  5\n",
      "250/938.875 loss: 0.439 acc: 0.858 \n",
      "Epoch:  5\n",
      "300/938.875 loss: 0.452 acc: 0.855 \n",
      "Epoch:  5\n",
      "350/938.875 loss: 0.461 acc: 0.856 \n",
      "Epoch:  5\n",
      "400/938.875 loss: 0.464 acc: 0.852 \n",
      "Epoch:  5\n",
      "450/938.875 loss: 0.467 acc: 0.856 \n",
      "Epoch:  5\n",
      "500/938.875 loss: 0.468 acc: 0.854 \n",
      "Epoch:  5\n",
      "550/938.875 loss: 0.469 acc: 0.852 \n",
      "Epoch:  5\n",
      "600/938.875 loss: 0.472 acc: 0.849 \n",
      "Epoch:  5\n",
      "650/938.875 loss: 0.469 acc: 0.849 \n",
      "Epoch:  5\n",
      "700/938.875 loss: 0.467 acc: 0.849 \n",
      "Epoch:  5\n",
      "750/938.875 loss: 0.471 acc: 0.852 \n",
      "Epoch:  5\n",
      "800/938.875 loss: 0.466 acc: 0.852 \n",
      "Epoch:  5\n",
      "850/938.875 loss: 0.467 acc: 0.85 \n",
      "Epoch:  5\n",
      "900/938.875 loss: 0.467 acc: 0.853 \n"
     ]
    },
    {
     "ename": "NameError",
     "evalue": "name 'datetime' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-20-bfaed8b2909c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m\u001b[0m\n\u001b[1;32m    133\u001b[0m     \u001b[0;31m#optimizer = Adam(model.parameters(), lr=lr)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    134\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 135\u001b[0;31m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msave\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstate_dict\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m'../models/'\u001b[0m\u001b[0;34m+\u001b[0m \u001b[0mdatetime\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mnow\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mstrftime\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m'%H-%d-%m-%Y'\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    136\u001b[0m \u001b[0mwriter\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mclose\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mNameError\u001b[0m: name 'datetime' is not defined"
     ]
    }
   ],
   "source": [
    "from torch.nn.utils import clip_grad_norm_\n",
    "from sklearn.metrics import roc_auc_score\n",
    "\n",
    "# training\n",
    "torch.cuda.empty_cache()   # Clearing Cache space for a fresh Model run\n",
    "\n",
    "EPOCHS = 5\n",
    "BATCH_SIZE_TRAIN = 8 # 4 if grad for all paramters\n",
    "BATCH_SIZE_VALID = 4\n",
    "\n",
    "# weight correction TODO\n",
    "weight_correction = sum(wc)* (1/wc[0]+ 1/wc[1]+ 1/wc[2]) / 3\n",
    "\n",
    "# training\n",
    "train_dataset = HatefulMemesDataset(data_train)\n",
    "train_loader = torch.utils.data.DataLoader(train_dataset, batch_size=BATCH_SIZE_TRAIN, num_workers=1, shuffle=True)\n",
    "\n",
    "# validation\n",
    "valid_dataset = HatefulMemesDataset(data_valid)\n",
    "valid_loader = torch.utils.data.DataLoader(valid_dataset, batch_size=BATCH_SIZE_VALID, shuffle=False)\n",
    "\n",
    "# loss fcn\n",
    "loss_fn = torch.nn.CrossEntropyLoss(reduction='sum', weight=weight_classes.float().to(device))\n",
    "\n",
    "# monitor train progress\n",
    "stats = {'train_loss': [], 'train_acc': [], 'valid_loss': [], 'valid_acc': [], 'val_rocauc': []}\n",
    "\n",
    "time_tot = []\n",
    "\n",
    "for epoch_num in range(EPOCHS):\n",
    "    #\n",
    "    train_loss = 0.\n",
    "    train_correct = 0.\n",
    "    \n",
    "    valid_loss = 0.\n",
    "    valid_correct = 0.\n",
    "    \n",
    "    # training ---------------------------------------------------\n",
    "    model.train()\n",
    "        \n",
    "    for step_num, batch in enumerate(train_loader):\n",
    "        \n",
    "        # sample = {'image': image, 'token_id': token_id, 'mask': mask, 'label': label}                \n",
    "        labels = batch['label'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "        token_ids = batch['token_id'].to(device)\n",
    "        # imgs, token_ids, masks, labels = tuple(t.to(device) for t in batch)\n",
    "        # print(str(torch.cuda.memory_allocated(device)/1000000 ) + 'M')\n",
    "        \n",
    "        logits = model(token_ids, masks)\n",
    "        preds = torch.reshape(torch.argmax(logits, dim=1), [-1,1])\n",
    "        \n",
    "        # account for class imbalance\n",
    "        eye = torch.ones(labels.shape, device=device)\n",
    "        weight_imbalance = (labels==0*eye).int()* wc[0] + (labels==eye).int()* wc[1]+ (labels==2*eye).int()* wc[2]\n",
    "   \n",
    "        # loss\n",
    "        batch_loss = loss_fn(logits, labels.squeeze())\n",
    "        train_loss += batch_loss.item()\n",
    "        train_correct += sum((preds==labels)* weight_imbalance).item()* weight_correction # adjust accuracy to [0,1]\n",
    "        \n",
    "        \n",
    "        '''\n",
    "        batch_loss = weighted_binary_cross_entropy(logits, labels.float())\n",
    "        train_loss += batch_loss.item()\n",
    "        train_correct += sum((torch.round(logits)==labels)).item()\n",
    "        '''\n",
    "        \n",
    "        # reset gradient and calculate new ones\n",
    "        model.zero_grad()\n",
    "        batch_loss.backward()\n",
    "        \n",
    "        # gradient clipping and backward pass\n",
    "        #clip_grad_norm_(parameters=model.parameters(), max_norm=1.0)\n",
    "        optimizer.step()\n",
    "\n",
    "        # logging\n",
    "        # clear_output(wait=True) -> from IPython.display import clear_output\n",
    "        if step_num%50==0 and step_num> 0:\n",
    "            print('Epoch: ', epoch_num + 1)\n",
    "            print(\"\\r\" + \"{0}/{1} loss: {2} acc: {3} \".format(step_num,\n",
    "                                                              len(train_data) / BATCH_SIZE_TRAIN,\n",
    "                                                              round(train_loss / (step_num + 1), 3),\n",
    "                                                              round(train_correct/ ((step_num+1)* BATCH_SIZE_TRAIN), 3)))\n",
    "    \n",
    "    # train stats\n",
    "    stats['train_loss'].append(train_loss / ((step_num+1)* BATCH_SIZE_TRAIN))\n",
    "    stats['train_acc'].append(train_correct / ((step_num+1)* BATCH_SIZE_TRAIN))\n",
    "    \n",
    "    writer.add_scalar('Loss/train', train_loss / ((step_num+1)* BATCH_SIZE_TRAIN), epoch_num)\n",
    "    writer.add_scalar('Accuracy/train', train_correct / ((step_num+1)* BATCH_SIZE_TRAIN), epoch_num)\n",
    "    \n",
    "    # validation ---------------------------------------\n",
    "    # TODO to calculate metrics\n",
    "    ypred = []\n",
    "    ytrue = []\n",
    "    weight = []\n",
    "\n",
    "    for step_num, batch in enumerate(valid_loader):\n",
    "        # sample = {'image': image, 'token_id': token_id, 'mask': mask, 'label': label}        \n",
    "        labels = batch['label'].to(device)\n",
    "        masks = batch['mask'].to(device)\n",
    "        token_ids = batch['token_id'].to(device)\n",
    "\n",
    "        # account for class imbalance (66% label 0, 33% label 1)\n",
    "        eye = torch.ones(labels.shape, device=device)\n",
    "        weight_imbalance = (labels==0*eye).int()* wc[0] + (labels==eye).int()* wc[1]+ (labels==2*eye).int()* wc[2]\n",
    "        \n",
    "        # loss\n",
    "        logits = model(token_ids, masks)\n",
    "        preds = torch.reshape(torch.argmax(logits, dim=1), [-1,1])\n",
    "        \n",
    "        batch_loss = loss_fn(logits, labels.squeeze())\n",
    "        valid_loss += batch_loss.item()\n",
    "        valid_correct += sum((preds==labels)* weight_imbalance).item()* weight_correction # adjust accuracy to [0,1]\n",
    "\n",
    "        '''\n",
    "        batch_loss = weighted_binary_cross_entropy(logits, labels.float())\n",
    "        valid_loss += batch_loss.item()\n",
    "        \n",
    "        valid_correct += sum((torch.round(logits)==labels)).item()\n",
    "        '''\n",
    "\n",
    "    # valid stats\n",
    "    stats['valid_loss'].append(valid_loss / ((step_num+1)* BATCH_SIZE_VALID))\n",
    "    stats['valid_acc'].append(valid_correct / ((step_num+1)* BATCH_SIZE_VALID))\n",
    "    \n",
    "    writer.add_scalar('Loss/valid', valid_loss / ((step_num+1)* BATCH_SIZE_VALID), epoch_num)\n",
    "    writer.add_scalar('Accuracy/valid', valid_correct / ((step_num+1)* BATCH_SIZE_VALID), epoch_num)\n",
    "\n",
    "    # optimizer lr decay: domain specific pre-training -> lr=2e-5\n",
    "    #lr*= 0.9\n",
    "    #optimizer = Adam(model.parameters(), lr=lr)\n",
    "\n",
    "torch.save(model.state_dict(), '../models/'+ datetime.now().strftime('%H-%d-%m-%Y'))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "metadata": {},
   "outputs": [],
   "source": [
    "from datetime import datetime\n",
    "torch.save(model.state_dict(), '../models/'+ datetime.now().strftime('%H-%d-%m-%Y'))\n",
    "writer.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "metadata": {
    "scrolled": true
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 864x288 with 2 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "fig, ax = plt.subplots(figsize=(12, 4), ncols=2)\n",
    "ax[0].plot(stats['train_loss'])\n",
    "ax[0].plot(stats['valid_loss'])\n",
    "ax[0].legend(['train', 'valid'])\n",
    "ax[0].set_ylabel('Loss')\n",
    "ax[0].set_yscale('log')\n",
    "\n",
    "ax[1].plot(stats['train_acc'])\n",
    "ax[1].plot(stats['valid_acc'])\n",
    "ax[1].legend(['train', 'valid'])\n",
    "ax[1].set_ylabel('Accuracy')\n",
    "\n",
    "plt.savefig('../twitter_pretraining_lr5e-6_dropout051.png')\n",
    "plt.show()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.9"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
